Introduction to AgentDB
A sub-millisecond memory engine built for autonomous agents with instant memory, local learning, and global coordination.

What is AgentDB?
AgentDB is an ultra-fast agent memory and vector database designed specifically for AI agents. It provides blazing-fast vector search, persistent reasoning patterns, and works seamlessly in both Node.js and browser environments with WASM support.

Key Features
Lightning Fast
Sub-millisecond query times with HNSW indexing. 12x faster search with 97% recall accuracy.

ReasoningBank
Built-in memory and learning system with pattern matching, experience curation, and memory optimization.

Universal Support
Works in Node.js and browsers with WASM. Same API, same performance everywhere.

MCP Integration
29 Model Context Protocol tools (5 core vector + 5 core agentdb + 9 frontier memory + 10 learning) for seamless AI agent integration, memory management, and adaptive learning with Claude Code.

Use Cases
ü§ñ Autonomous AI agents with long-term memory
üí¨ Conversational AI with context retention
üîç Semantic search and recommendation systems
üìä Knowledge base management
üß† Pattern recognition and learning systems

Installation
Get started with AgentDB in your project using npm, yarn, or npx.

Installation & Setup
AgentDB v1.3.9 supports both Node.js and browser environments with the same powerful API.

NPM Installation (Node.js)
Install AgentDB as a dependency in your Node.js project:


npm install agentdb
Browser Installation (CDN)
Use AgentDB directly in the browser via CDN (no build step required):


<!-- AgentDB v1.3.9 - Browser Bundle -->
<script src="https://unpkg.com/agentdb@1.3.9/dist/agentdb.min.js"></script>
<script>
  // AgentDB is now available globally
  AgentDB.onReady(() => {
    console.log('AgentDB v' + AgentDB.version + ' ready!');
    // Start using the database
  });
</script>
‚ö° Browser Bundle Features
‚Ä¢ WASM-powered SQLite database (89KB bundle)
‚Ä¢ Zero dependencies - just one script tag
‚Ä¢ Backward compatible with v1.0.7 API
‚Ä¢ 5 pre-built tables (vectors, patterns, episodes, causal_edges, skills)
‚Ä¢ Full SQL support with async initialization
Browser Usage Example
Complete HTML example using AgentDB in the browser:


<!DOCTYPE html>
<html>
<head>
  <title>AgentDB Browser Demo</title>
  <script src="https://unpkg.com/agentdb@1.3.9/dist/agentdb.min.js"></script>
</head>
<body>
  <h1>AgentDB Browser Example</h1>
  <div id="output"></div>
  
  <script>
    AgentDB.onReady(async () => {
      // Create and initialize database
      const db = new AgentDB.Database();
      await db.initializeAsync();
      
      // Insert some patterns
      db.insert('patterns', {
        pattern: 'causal-reasoning',
        metadata: JSON.stringify({ domain: 'logic', quality: 'high' })
      });
      
      db.insert('patterns', {
        pattern: 'optimization',
        metadata: JSON.stringify({ domain: 'ml', quality: 'medium' })
      });
      
      // Query data
      const results = db.exec('SELECT * FROM patterns');
      
      // Display results
      const output = document.getElementById('output');
      if (results.length > 0) {
        const { columns, values } = results[0];
        output.innerHTML = '<h2>Stored Patterns:</h2>';
        values.forEach(row => {
          const obj = {};
          columns.forEach((col, i) => obj[col] = row[i]);
          output.innerHTML += `<pre>${JSON.stringify(obj, null, 2)}</pre>`;
        });
      }
      
      // Export database
      const data = db.export();
      console.log('Database size:', data.length, 'bytes');
      
      // Save to localStorage
      localStorage.setItem('agentdb', 
        btoa(String.fromCharCode(...data))
      );
    });
  </script>
</body>
</html>
Yarn Installation
Or use Yarn if you prefer:


yarn add agentdb
Quick Start with NPX
Try AgentDB instantly without installation:


npx agentdb
Requirements
‚Ä¢ Node.js 16.0.0 or higher
‚Ä¢ npm 7.0.0 or higher (or equivalent yarn/pnpm version)
‚Ä¢ For WASM support: Modern browser with WebAssembly enabled
Browser Usage
AgentDB can be used directly in the browser via WASM (optimized 89KB bundle):


<script type="module">
  import { SQLiteVectorDB } from 'https://unpkg.com/agentdb@latest/dist/agentdb.min.js';

  const db = new SQLiteVectorDB({ memoryMode: true, backend: 'wasm' });
  await db.initializeAsync();
  // Database ready to use
</script>
Try the Code Wizard
New to AgentDB? Use our interactive Code Wizard on the Demo page to generate a complete, customized WASM example in 5 easy steps. Configure database settings, quantization, HNSW indexing, and choose from multiple example types with live preview.

‚Ä¢ Interactive 5-step configuration wizard
‚Ä¢ Live code preview in browser
‚Ä¢ Copy complete HTML example to clipboard
‚Ä¢ Multiple example types (RAG, semantic search, learning, clustering)

Quick Start Guide
Get up and running with AgentDB in minutes.

1. Initialize the Database

import AgentDB from 'agentdb';

// Create an in-memory database
const db = new AgentDB({
  memory: true
});

// Or persist to disk
const persistentDb = new AgentDB({
  path: './data/agent.db'
});
2. Store Vectors

// Store a vector with metadata
await db.store({
  id: 'user-query-1',
  vector: [0.1, 0.2, 0.3, 0.4, 0.5],
  metadata: {
    type: 'query',
    timestamp: Date.now(),
    content: 'What is AgentDB?'
  }
});
3. Query Similar Vectors

// Find similar vectors
const results = await db.query({
  vector: [0.1, 0.2, 0.3, 0.4, 0.5],
  k: 5, // Return top 5 results
  threshold: 0.8 // Minimum similarity score
});

results.forEach(result => {
  console.log('ID:', result.id);
  console.log('Score:', result.score);
  console.log('Metadata:', result.metadata);
});
4. Use ReasoningBank

// Store reasoning patterns
await db.reasoningBank.store({
  pattern: 'problem-solving',
  context: 'User needs help with installation',
  reasoning: 'Check dependencies, verify versions, provide step-by-step guide',
  outcome: 'success',
  confidence: 0.95
});

// Query similar patterns
const patterns = await db.reasoningBank.query({
  context: 'User installation issue',
  k: 3
});
üéâ That's it!
You're now ready to build intelligent agents with AgentDB. Explore the API Reference for more advanced features and configuration options.

API Reference
Complete API documentation for AgentDB.

Constructor

new AgentDB(options: AgentDBOptions)
Options
Property	Type	Description
path	string	Database file path (optional)
memory	boolean	Use in-memory database
dimensions	number	Vector dimensions (default: 384)
maxElements	number	Maximum vectors (default: 10000)
Core Methods
store()
Store a vector with metadata.


await db.store({
  id: string,
  vector: number[],
  metadata?: Record<string, any>
})
query()
Query for similar vectors.


await db.query({
  vector: number[],
  k?: number,
  threshold?: number,
  filter?: Record<string, any>
})
delete()
Delete a vector by ID.


await db.delete(id: string)
update()
Update vector metadata.


await db.update(id: string, {
  metadata: Record<string, any>
})
ReasoningBank Methods
reasoningBank.store()

await db.reasoningBank.store({
  pattern: string,
  context: string,
  reasoning: string,
  outcome: string,
  confidence?: number
})
reasoningBank.query()

await db.reasoningBank.query({
  context: string,
  k?: number,
  minConfidence?: number
})

Learning Plugins
AgentDB provides 10 advanced learning algorithms as pluggable modules for specialized agent training.

Plugin System
Learning plugins extend AgentDB's capabilities with specialized machine learning algorithms. Each plugin implements a specific learning paradigm and can be used independently or combined for hybrid learning approaches.

All plugins are available in the agentdb/dist/plugins/implementations/ directory and can be imported directly.

CLI Plugin Creator
Create custom learning plugins with an interactive wizard:


npx agentdb create-plugin

# Or using the CLI directly
agentdb create-plugin --name my-plugin --type reinforcement
Available Learning Plugins
Q-Learning (Recommended)
Reinforcement Learning
Model-free reinforcement learning for action-value estimation.


import { QLearning } from 'agentdb/dist/plugins/implementations/q-learning';

const qlearning = new QLearning({
  learningRate: 0.1,
  discountFactor: 0.95,
  epsilon: 0.1 // Exploration rate
});
Best for: Discrete action spaces, game AI, navigation

SARSA
Reinforcement Learning
On-policy temporal difference learning algorithm.


import { SARSA } from 'agentdb/dist/plugins/implementations/sarsa';

const sarsa = new SARSA({
  learningRate: 0.1,
  discountFactor: 0.99
});
Best for: Real-time decision making, risk-sensitive tasks

Actor-Critic
Reinforcement Learning
Policy gradient method combining value and policy optimization.


import { ActorCritic } from 'agentdb/dist/plugins/implementations/actor-critic';

const ac = new ActorCritic({
  actorLearningRate: 0.001,
  criticLearningRate: 0.01
});
Best for: Continuous control, robotics, complex environments

Active Learning
Semi-Supervised
Query strategy for selecting most informative training examples.


import { ActiveLearning } from 'agentdb/dist/plugins/implementations/active-learning';

const al = new ActiveLearning({
  strategy: 'uncertainty', // or 'diversity', 'margin'
  batchSize: 10
});
Best for: Limited labeled data, human-in-the-loop systems

Curriculum Learning
Training Strategy
Progressive training from simple to complex examples.


import { CurriculumLearning } from 'agentdb/dist/plugins/implementations/curriculum-learning';

const cl = new CurriculumLearning({
  stages: ['easy', 'medium', 'hard'],
  transitionCriteria: 0.9 // Success threshold
});
Best for: Complex task learning, transfer learning

Multi-Task Learning
Transfer Learning
Learn multiple related tasks simultaneously to improve generalization.


import { MultiTaskLearning } from 'agentdb/dist/plugins/implementations/multi-task-learning';

const mtl = new MultiTaskLearning({
  tasks: ['classification', 'regression'],
  sharedLayers: 3
});
Best for: Related tasks, data efficiency, shared representations

Federated Learning
Distributed Learning
Train models across decentralized devices without sharing raw data.


import { FederatedLearning } from 'agentdb/dist/plugins/implementations/federated-learning';

const fl = new FederatedLearning({
  aggregationStrategy: 'fedavg',
  clientSampleRate: 0.1
});
Best for: Privacy-preserving ML, edge devices, distributed agents

Neural Architecture Search
AutoML
Automatically discover optimal neural network architectures.


import { NAS } from 'agentdb/dist/plugins/implementations/neural-architecture-search';

const nas = new NAS({
  searchSpace: 'efficient',
  maxTrials: 100,
  objective: 'accuracy'
});
Best for: Model optimization, custom architectures, performance tuning

Adversarial Training
Robustness
Train robust models using adversarial examples.


import { AdversarialTraining } from 'agentdb/dist/plugins/implementations/adversarial-training';

const at = new AdversarialTraining({
  epsilon: 0.3, // Perturbation budget
  method: 'FGSM' // or 'PGD', 'C&W'
});
Best for: Security-critical applications, robust AI

Decision Transformer
Offline RL
Sequence modeling approach to offline reinforcement learning.


import { DecisionTransformer } from 'agentdb/dist/plugins/implementations/decision-transformer';

const dt = new DecisionTransformer({
  contextLength: 20,
  returnConditioned: true
});
Best for: Learning from logged data, behavioral cloning

Vector Quantization
Reduce memory usage and accelerate search with advanced compression techniques.

Why Quantization?
Vector quantization compresses high-dimensional embeddings while preserving similarity relationships. This enables storing millions of vectors in limited memory and achieving 10-100x faster searches with minimal accuracy loss.

Available Quantization Methods
Scalar Quantization
RECOMMENDED
Maps float32 vectors to int8/int16 with learned min/max bounds.


import { SQLiteVectorDB } from 'agentdb';

const db = new SQLiteVectorDB({
  enableQuantization: true,
  quantizationType: 'scalar',
  quantizationBits: 8 // 4-8x compression
});

await db.initializeAsync();
Performance:

‚Ä¢ Compression: 4-16x (depending on bits)
‚Ä¢ Speed: 2-4x faster search
‚Ä¢ Accuracy: 85-95% (int8) to 95-99% (int16)
Best for: General-purpose use, balanced speed/accuracy

Product Quantization (PQ)
Splits vectors into subvectors and quantizes each independently.


const db = new SQLiteVectorDB({
  enableQuantization: true,
  quantizationType: 'product',
  subvectors: 8, // Split into 8 parts
  codebookSize: 256 // 8-bit codes
});
Performance:

‚Ä¢ Compression: 16-64x
‚Ä¢ Speed: 10-20x faster search
‚Ä¢ Accuracy: 70-85%
Best for: Large-scale systems (1M+ vectors), high compression needs

Binary Quantization
Ultra-fast 1-bit quantization for maximum speed.


const db = new SQLiteVectorDB({
  enableQuantization: true,
  quantizationType: 'binary',
  threshold: 0.0 // Sign threshold
});
Performance:

‚Ä¢ Compression: 256x (32-bit to 1-bit)
‚Ä¢ Speed: 32x faster with Hamming distance
‚Ä¢ Accuracy: 60-75%
Best for: Initial filtering, retrieval cascades, real-time systems

Optimized Product Quantization (OPQ)
Learns optimal rotation before PQ for better accuracy.


const db = new SQLiteVectorDB({
  enableQuantization: true,
  quantizationType: 'optimized-pq',
  subvectors: 8,
  codebookSize: 256,
  rotationIterations: 20
});
Performance:

‚Ä¢ Compression: 16-64x (same as PQ)
‚Ä¢ Speed: 10-20x faster search
‚Ä¢ Accuracy: 75-90% (+5-10% vs PQ)
Best for: Maximum accuracy with high compression

Choosing the Right Method
Use Case	Recommended
General purpose	Scalar (int8)
Large scale (1M+ vectors)	Product Quantization
Real-time/low latency	Binary
Best accuracy + compression	Optimized PQ

MCP Tools
Model Context Protocol tools for seamless AI agent integration with Claude Code and other AI assistants.

What are MCP Tools?
AgentDB provides 29 MCP (Model Context Protocol) tools that enable AI assistants like Claude Code to directly interact with your vector database, manage learning sessions, and coordinate agent behaviors. All tools are available immediately when the MCP server starts.

MCP Server Setup
Add AgentDB as an MCP server to Claude Code:


# Add MCP server
claude mcp add agentdb npx agentdb mcp

# Start the server
npx agentdb mcp start
Core Vector Database Tools (5)
Essential vector database operations for storing, searching, and managing embeddings.

1. agentdb_init
Initialize a new AgentDB vector database with configuration.


// Initialize database
{
  "backend": "native",
  "memoryMode": true,
  "enableQuantization": false,
  "enableQueryCache": true
}
2. agentdb_insert
Insert a single vector with metadata.


// Insert vector
{
  "vector": {
    "embedding": [0.1, 0.2, 0.3, ...],
    "metadata": {
      "type": "document",
      "content": "Example text"
    }
  }
}
3. agentdb_insert_batch
Insert multiple vectors in batch for better performance.


// Batch insert
{
  "vectors": [
    { "embedding": [...], "metadata": {...} },
    { "embedding": [...], "metadata": {...} }
  ]
}
4. agentdb_search
Perform k-nearest neighbor search with cosine similarity.


// Search for similar vectors
{
  "queryEmbedding": [0.1, 0.2, 0.3, ...],
  "k": 5,
  "threshold": 0.7,
  "metric": "cosine"
}
5. agentdb_delete
Delete a vector by ID from the database.


// Delete vector
{
  "id": "vector-123"
}
6. agentdb_stats
Get comprehensive database statistics including cache and compression metrics.


// Get stats (no parameters needed)
7. agentdb_pattern_store
Store reasoning patterns in ReasoningBank for future learning.


// Store pattern
{
  "pattern": {
    "embedding": [...],
    "taskType": "code-review",
    "approach": "Check types first",
    "successRate": 0.9,
    "metadata": {
      "domain": "typescript",
      "complexity": "medium"
    }
  }
}
8. agentdb_pattern_search
Search for similar reasoning patterns based on task embedding.


// Search patterns
{
  "taskEmbedding": [...],
  "k": 5,
  "threshold": 0.7,
  "filters": {
    "domain": "typescript",
    "minSuccessRate": 0.8
  }
}
9. agentdb_pattern_stats
Get statistics about stored reasoning patterns.


// Get pattern stats (no parameters needed)
10. agentdb_clear_cache
Clear the query cache to free memory or force fresh queries.


// Clear cache (no parameters needed)
Frontier Memory Tools (9)
Advanced memory capabilities including Reflexion learning, skill management, and causal reasoning.

11. reflexion_store
Store episodes with self-critique for reflexive learning.


// Store reflexion episode
{
  "task": "implement auth",
  "action": "created middleware",
  "outcome": "success",
  "reflection": "Should validate tokens first",
  "metadata": {
    "duration": 300,
    "complexity": "medium"
  }
}
12. reflexion_retrieve
Retrieve past episodes for learning from experience.


// Retrieve episodes
{
  "task": "implement auth",
  "k": 5,
  "only_successes": true
}
13. skill_create
Create reusable skills from successful patterns.


// Create skill
{
  "name": "validate-jwt",
  "description": "JWT token validation",
  "implementation": "function validateToken(token) {...}",
  "metadata": {
    "language": "typescript",
    "domain": "security"
  }
}
14. skill_search
Search for skills by semantic similarity.


// Search skills
{
  "query": "authentication helper",
  "k": 3,
  "threshold": 0.7
}
15. causal_add_edge
Add causal relationships to track cause-effect patterns.


// Add causal edge
{
  "cause": "added caching",
  "effect": "reduced latency",
  "uplift": 0.45,
  "confidence": 0.85
}
16. causal_query
Query causal relationships and effects.


// Query causality
{
  "cause": "added caching",
  "min_confidence": 0.7
}
17. recall_with_certificate
Explainable recall with provenance certificates.


// Recall with proof
{
  "query": "error handling pattern",
  "k": 3,
  "include_provenance": true
}
18. learner_discover
Auto-discover causal patterns from data.


// Discover patterns
{
  "min_support": 0.3,
  "min_confidence": 0.7,
  "max_patterns": 10
}
19. db_stats
Get comprehensive database statistics.


// Get stats (no parameters needed)
Learning System Tools (10)
Adaptive learning and reinforcement capabilities for intelligent agent behavior.

20. learning_start_session
Start a new learning session for adaptive action selection.


// Start session
{
  "userId": "agent-001",
  "sessionType": "coding",
  "config": {
    "learningRate": 0.1,
    "discountFactor": 0.95
  }
}
21. learning_end_session
End a learning session and save the learned policy.


// End session
{
  "sessionId": "session-123"
}
22. learning_predict
Get AI-recommended action for current state with confidence scores.


// Get prediction
{
  "sessionId": "session-123",
  "currentState": {
    "taskDescription": "Fix bug",
    "availableTools": ["read", "edit", "bash"]
  },
  "availableTools": ["read", "edit", "bash"]
}
23. learning_feedback
Provide feedback on action quality to improve learning.


// Submit feedback
{
  "sessionId": "session-123",
  "actionId": "action-456",
  "feedback": {
    "success": true,
    "rating": 4.5,
    "dimensions": {
      "accuracy": 0.9,
      "speed": 0.8
    }
  }
}
24. learning_train
Train policy on collected experiences.


// Train model
{
  "sessionId": "session-123",
  "options": {
    "epochs": 10,
    "batchSize": 32,
    "learningRate": 0.1
  }
}
25. learning_metrics
Get learning performance metrics and statistics.


// Get metrics
{
  "sessionId": "session-123",
  "period": "session"
}
26. learning_transfer
Transfer learning from one task to another.


// Transfer learning
{
  "sourceSessionId": "session-123",
  "targetSessionId": "session-456",
  "similarity": 0.7
}
27. learning_explain
Explain why an action was recommended.


// Get explanation
{
  "sessionId": "session-123",
  "state": {
    "taskDescription": "Debug error",
    "availableTools": ["grep", "read"]
  }
}
28. experience_record
Record a tool execution as learning experience.


// Record experience
{
  "sessionId": "session-123",
  "toolName": "edit",
  "args": {...},
  "result": "success",
  "outcome": {
    "success": true,
    "executionTime": 150
  }
}
29. reward_signal
Calculate reward signal for an outcome.


// Calculate reward
{
  "outcome": {
    "success": true,
    "executionTime": 150
  },
  "context": {
    "userId": "agent-001",
    "sessionId": "session-123",
    "taskType": "coding"
  }
}
‚ú® All Tools Available Immediately
All 29 MCP tools are initialized and available as soon as the MCP server starts. Learning tools use a temporary in-memory database until you explicitly initialize a persistent database with agentdb_init.

ReasoningBank
Built-in memory and learning system for AI agents.

What is ReasoningBank?
ReasoningBank is a comprehensive memory and learning system that allows AI agents to:

‚Ä¢ Store and retrieve reasoning patterns
‚Ä¢ Learn from past experiences
‚Ä¢ Track performance metrics
‚Ä¢ Optimize memory usage
‚Ä¢ Adapt strategies over time
Components
1. PatternMatcher
Stores and retrieves reasoning patterns based on context similarity.


// Store a reasoning pattern
await db.reasoningBank.patternMatcher.store({
  pattern: 'debugging',
  context: 'Error in async function',
  solution: 'Check promise handling and error catching',
  effectiveness: 0.9
});

// Find similar patterns
const matches = await db.reasoningBank.patternMatcher.match({
  context: 'Promise rejection in async code',
  k: 5
});
2. ExperienceCurator
Manages task experiences and tracks performance over time.


// Record an experience
await db.reasoningBank.experienceCurator.record({
  task: 'code-review',
  context: 'React component optimization',
  actions: ['Identify re-renders', 'Add memoization'],
  outcome: 'success',
  quality: 0.92
});

// Query similar experiences
const experiences = await db.reasoningBank.experienceCurator.query({
  task: 'code-review',
  minQuality: 0.8
});
3. MemoryOptimizer
Optimizes long-term storage by consolidating and pruning memories.


// Optimize memory
await db.reasoningBank.memoryOptimizer.optimize({
  pruneThreshold: 0.5, // Remove low-quality memories
  consolidateThreshold: 0.95, // Merge similar memories
  maxAge: 30 * 24 * 60 * 60 * 1000 // 30 days
});

// Get optimization stats
const stats = await db.reasoningBank.memoryOptimizer.getStats();
Usage Example

// Complete ReasoningBank workflow
const agent = new AgentDB({ memory: true });

// 1. Agent encounters a problem
const problem = "How to handle rate limiting in API calls?";

// 2. Query for similar past experiences
const pastExperiences = await agent.reasoningBank.query({
  context: problem,
  k: 3,
  minConfidence: 0.7
});

// 3. Apply learned pattern or create new reasoning
let solution;
if (pastExperiences.length > 0) {
  solution = pastExperiences[0].reasoning;
} else {
  solution = "Implement exponential backoff with retry logic";
}

// 4. Store the new experience
await agent.reasoningBank.store({
  pattern: 'rate-limiting',
  context: problem,
  reasoning: solution,
  outcome: 'success',
  confidence: 0.85
});

Frontier Memory Features
Advanced memory patterns that go beyond simple vector storage to enable true cognitive capabilities for autonomous AI agents.

Overview
CLI Reference
SDK Guide
What Are Frontier Memory Features?
Traditional vector databases store embeddings and retrieve similar items. Frontier Memory goes beyond this with cognitive capabilities that enable agents to:

Learn from experience by storing episodic memories with self-critique
Build reusable skills from successful patterns automatically
Understand causality ‚Äî what actions lead to which outcomes
Explain decisions with cryptographic proof of completeness
Discover patterns automatically while you sleep
Episodic Replay
Reflexion Memory
Learn from experience with self-critique and episodic replay

Lifelong Learning
Skill Library
Auto-consolidate successful patterns into reusable skills

Intervention-Based
Causal Memory
Track p(y|do(x)) not just p(y|x) ‚Äî intervention-based causality

Provenance
Explainable Recall
Provenance certificates with cryptographic Merkle proofs

Utility-Based
Causal Recall
U = Œ±¬∑similarity + Œ≤¬∑uplift ‚àí Œ≥¬∑latency

Automated
Nightly Learner
Automated causal discovery with doubly robust learning

Quick Start
Get started in seconds with the CLI. All features work out of the box:


# Install globally
npm install -g agentdb

# Store your first episode with critique
agentdb reflexion store "session-1" "fix_auth_bug" 0.95 true \
  "OAuth2 flow worked perfectly" "login failing" "fixed tokens" 1200 500

# Search for similar experiences
agentdb reflexion retrieve "authentication issues" 10 0.8

# View database stats
agentdb db stats
Practical Use Cases
üêõ Debugging
Store every debugging session with what worked and what didn't. Future bugs? Retrieve similar past solutions instantly.

üöÄ Feature Development
Track which approaches succeeded. Build a library of proven patterns that can be reused across projects.

‚ö° Performance Optimization
Learn which optimizations actually improve performance. Causal memory shows cause-and-effect, not just correlation.

üèóÔ∏è Architecture Decisions
Document why certain architectural choices succeeded or failed. Build institutional knowledge over time.

Ready to Get Started?
Install AgentDB and start using frontier memory features in seconds. Build AI agents that learn from experience, understand causality, and improve over time.

$
npm install -g agentdb

HNSW Index
Hierarchical Navigable Small World index for ultra-fast vector search.

Performance Benefits
12x
Faster than linear search
97%
Recall accuracy
<1ms
Query time
What is HNSW?
HNSW (Hierarchical Navigable Small World) is a graph-based algorithm for approximate nearest neighbor search. It creates a multi-layer graph structure that allows for logarithmic search complexity while maintaining high recall accuracy.

Configuration

const db = new AgentDB({
  memory: true,
  hnsw: {
    M: 16,              // Number of connections per node
    efConstruction: 200, // Search quality during build
    efSearch: 50,       // Search quality during query
    metric: 'cosine'    // Distance metric
  }
});
Parameters
Parameter	Default	Description
M	16	Connections per node (higher = better accuracy, more memory)
efConstruction	200	Build quality (higher = better index, slower build)
efSearch	50	Query quality (higher = better recall, slower search)
metric	cosine	Distance metric (cosine, euclidean, dot)
Tuning for Performance
Optimization Guidelines
For speed: Lower M (8-12), lower efSearch (10-30)
For accuracy: Higher M (16-32), higher efSearch (50-100)
For large datasets: Increase efConstruction (200-400)
For real-time apps: Use cosine metric, M=16, efSearch=20-30

Advanced Features
Powerful capabilities for distributed agents, synchronization, and advanced query building.

VectorQueryBuilder
Fluent API for building complex vector queries with filters and options:


import { VectorQueryBuilder } from 'agentdb';

const results = await db
  .queryBuilder()
  .vector([0.1, 0.2, 0.3, ...])
  .k(10)
  .threshold(0.8)
  .filter({ category: 'technical', language: 'typescript' })
  .metric('cosine')
  .includeMetadata()
  .execute();

// Complex filtering
const results = await db
  .queryBuilder()
  .vector(embedding)
  .k(20)
  .filter({
    timestamp: { $gte: Date.now() - 86400000 }, // Last 24 hours
    confidence: { $gt: 0.9 },
    tags: { $contains: 'production' }
  })
  .sort('confidence', 'desc')
  .execute();
Query Builder Methods
Method	Description
.vector(arr)	Set query vector
.k(n)	Number of results
.threshold(n)	Minimum similarity score (0-1)
.filter(obj)	Metadata filtering
.metric(str)	Distance metric (cosine, euclidean, dot)
.sort(field, order)	Sort results by metadata field
.includeMetadata()	Include full metadata in results
QUIC Sync Protocol
Low-latency synchronization for distributed agent networks using QUIC protocol:


import { SQLiteVectorDB, QuicSync } from 'agentdb';

// Initialize database with QUIC sync
const db = new SQLiteVectorDB({
  path: './agent.db',
  sync: {
    enabled: true,
    protocol: 'quic',
    peers: [
      'quic://agent-1.local:4433',
      'quic://agent-2.local:4433'
    ],
    syncInterval: 5000 // 5 seconds
  }
});

await db.initializeAsync();

// Manual sync trigger
await db.sync.push(); // Push local changes
await db.sync.pull(); // Pull remote changes
await db.sync.bidirectional(); // Full sync

// Listen for sync events
db.on('sync:start', () => console.log('Sync started'));
db.on('sync:complete', (stats) => console.log('Synced:', stats));
db.on('sync:conflict', (conflict) => db.resolveConflict(conflict));
Why QUIC for Agent Sync?
QUIC provides ultra-low latency (10-50ms), multiplexed streams, and built-in encryption for secure agent-to-agent communication. Perfect for real-time distributed AI systems.

‚Ä¢ 0-RTT resumption: Instant reconnection for mobile agents
‚Ä¢ Stream multiplexing: No head-of-line blocking
‚Ä¢ Built-in TLS 1.3: Encrypted by default
‚Ä¢ Connection migration: Seamless network switching
Distributed Coordination

// Consensus-based updates
import { DistributedDB } from 'agentdb';

const db = new DistributedDB({
  nodeId: 'agent-worker-1',
  consensus: {
    algorithm: 'raft', // or 'paxos', 'pbft'
    quorum: 3,
    timeout: 1000
  },
  peers: ['agent-1', 'agent-2', 'agent-3']
});

// Propose update (requires quorum approval)
const result = await db.propose({
  operation: 'insert',
  vector: [...],
  metadata: {...}
});

// Listen for consensus events
db.on('consensus:achieved', (proposal) => {
  console.log('Cluster agreed on:', proposal);
});

db.on('consensus:failed', (proposal) => {
  console.log('No consensus, rolling back:', proposal);
});
Cross-Session Memory Persistence

// Export session state
const snapshot = await db.exportSession({
  includeVectors: true,
  includeReasoningBank: true,
  includeMetrics: true
});

// Save to file or cloud storage
await fs.writeFile('./session-backup.json', JSON.stringify(snapshot));

// Restore in new session
const db2 = new SQLiteVectorDB({ memoryMode: true });
await db2.initializeAsync();
await db2.importSession(snapshot);

// Now db2 has all vectors, patterns, and metrics from db
Plugin Registry

// Register custom learning plugin
import { PluginRegistry } from 'agentdb';

const registry = new PluginRegistry();

// Register plugin
registry.register({
  name: 'custom-rl',
  version: '1.0.0',
  type: 'learning',
  implementation: CustomRLPlugin,
  metadata: {
    author: 'your-name',
    description: 'Custom reinforcement learning algorithm'
  }
});

// Load plugin
const plugin = await registry.load('custom-rl');
const learner = new plugin({
  learningRate: 0.01
});

// List available plugins
const plugins = registry.list({ type: 'learning' });
console.log(plugins); // All learning plugins
Advanced Index Options

import { OptimizedHNSWIndex } from 'agentdb';

// Create optimized index with custom configuration
const index = new OptimizedHNSWIndex({
  dimensions: 1536,
  M: 32, // Higher connectivity for better recall
  efConstruction: 400,
  efSearch: 100,

  // Advanced options
  levelMultiplier: 1 / Math.log(2),
  maxLevel: 6,
  pruneConnections: true,

  // Performance tuning
  cacheSize: 10000,
  prefetchDepth: 2,
  parallelism: 4 // Multi-threaded search
});

// Build index
await index.buildFromVectors(vectors);

// Batch insert with optimizations
await index.insertBatch(newVectors, {
  batchSize: 1000,
  parallel: true,
  skipDuplicates: true
});
Performance Comparison
Feature	Standard	Advanced
Query Latency	~1-2ms	~0.3-0.8ms
Batch Insert	1000/sec	10,000/sec
Sync Latency	N/A	10-50ms (QUIC)
Memory Efficiency	Baseline	4-32x (with quantization)


Examples
Real-world examples and use cases for AgentDB.

Conversational AI Agent

class ConversationalAgent {
  constructor() {
    this.db = new AgentDB({ memory: true });
    this.embeddings = new EmbeddingModel();
  }

  async remember(message, response) {
    const embedding = await this.embeddings.encode(message);
    
    await this.db.store({
      id: Date.now().toString(),
      vector: embedding,
      metadata: {
        message,
        response,
        timestamp: Date.now()
      }
    });
  }

  async recall(query) {
    const embedding = await this.embeddings.encode(query);
    
    const results = await this.db.query({
      vector: embedding,
      k: 5,
      threshold: 0.7
    });

    return results.map(r => r.metadata);
  }

  async chat(userMessage) {
    // Recall relevant context
    const context = await this.recall(userMessage);
    
    // Generate response using context
    const response = await this.generateResponse(userMessage, context);
    
    // Remember this interaction
    await this.remember(userMessage, response);
    
    return response;
  }
}
Semantic Search Engine

class SemanticSearch {
  constructor() {
    this.db = new AgentDB({ 
      path: './search.db',
      dimensions: 768
    });
  }

  async indexDocuments(documents) {
    for (const doc of documents) {
      const embedding = await this.embeddings.encode(doc.content);
      
      await this.db.store({
        id: doc.id,
        vector: embedding,
        metadata: {
          title: doc.title,
          content: doc.content,
          tags: doc.tags,
          url: doc.url
        }
      });
    }
  }

  async search(query, filters = {}) {
    const queryEmbedding = await this.embeddings.encode(query);
    
    const results = await this.db.query({
      vector: queryEmbedding,
      k: 20,
      filter: filters
    });

    return results.map(r => ({
      ...r.metadata,
      score: r.score
    }));
  }
}
Recommendation System

class RecommendationEngine {
  constructor() {
    this.db = new AgentDB({ memory: true });
  }

  async trackInteraction(userId, itemId, interaction) {
    // Create interaction embedding
    const embedding = this.createInteractionVector(interaction);
    
    await this.db.store({
      id: `${userId}-${itemId}-${Date.now()}`,
      vector: embedding,
      metadata: {
        userId,
        itemId,
        type: interaction.type,
        rating: interaction.rating,
        timestamp: Date.now()
      }
    });
  }

  async getRecommendations(userId, k = 10) {
    // Get user's interaction profile
    const userProfile = await this.getUserProfile(userId);
    
    // Find similar interaction patterns
    const similar = await this.db.query({
      vector: userProfile,
      k: k * 2,
      filter: { userId: { $ne: userId } }
    });

    // Extract unique item recommendations
    const recommendations = this.deduplicateItems(similar);
    
    return recommendations.slice(0, k);
  }
}

Configuration
Advanced configuration options for AgentDB.

Database Configuration

const db = new AgentDB({
  // Storage
  path: './data/agent.db',
  memory: false,
  
  // Vector settings
  dimensions: 384,
  maxElements: 100000,
  
  // HNSW index
  hnsw: {
    M: 16,
    efConstruction: 200,
    efSearch: 50,
    metric: 'cosine'
  },
  
  // Performance
  cacheSize: 1000,
  batchSize: 100,
  
  // Logging
  logLevel: 'info'
});
Environment Variables
Variable	Description	Default
AGENTDB_PATH	Default database path	./agent.db
AGENTDB_LOG_LEVEL	Logging level	info
AGENTDB_CACHE_SIZE	Cache size	1000
MCP Server Configuration

import { MCPServer } from '@agentdb/mcp-server';

const server = new MCPServer({
  database: db,
  port: 3000,
  host: '0.0.0.0',
  
  // Authentication
  auth: {
    enabled: true,
    secret: process.env.MCP_SECRET,
    algorithm: 'HS256'
  },
  
  // Rate limiting
  rateLimit: {
    windowMs: 15 * 60 * 1000,
    max: 100
  },
  
  // CORS
  cors: {
    origin: '*',
    credentials: true
  }
});

await server.start();

Best Practices
Guidelines for building production-ready applications with AgentDB.

General Guidelines
‚Ä¢ Always normalize vectors before storing
‚Ä¢ Use appropriate vector dimensions for your use case
‚Ä¢ Implement proper error handling and retry logic
‚Ä¢ Monitor memory usage in production
‚Ä¢ Use batch operations for bulk inserts
‚Ä¢ Regularly backup persistent databases
Vector Normalization

function normalizeVector(vector) {
  const magnitude = Math.sqrt(
    vector.reduce((sum, val) => sum + val * val, 0)
  );
  return vector.map(val => val / magnitude);
}

// Use before storing
const normalized = normalizeVector(embedding);
await db.store({
  id: 'doc-1',
  vector: normalized,
  metadata: { ... }
});
Error Handling

async function safeQuery(db, vector, retries = 3) {
  for (let i = 0; i < retries; i++) {
    try {
      return await db.query({ vector, k: 10 });
    } catch (error) {
      if (i === retries - 1) throw error;
      
      console.warn(`Query failed, retry ${i + 1}/${retries}`);
      await new Promise(r => setTimeout(r, 1000 * (i + 1)));
    }
  }
}
Batch Operations

async function batchStore(db, items, batchSize = 100) {
  for (let i = 0; i < items.length; i += batchSize) {
    const batch = items.slice(i, i + batchSize);
    
    await Promise.all(
      batch.map(item => db.store(item))
    );
    
    // Optional: Add delay between batches
    if (i + batchSize < items.length) {
      await new Promise(r => setTimeout(r, 100));
    }
  }
}
Memory Management
Memory Optimization Tips
Use lower dimensions:384 dims is often sufficient, avoids overhead of 768 or 1536
Prune old data:Regularly remove outdated or low-quality vectors
Use disk storage:For large datasets, persist to disk rather than memory
Monitor usage:Track memory consumption and set limits
Production Checklist
‚úì Set up automated backups
‚úì Implement monitoring and alerting
‚úì Use environment variables for configuration
‚úì Enable proper logging
‚úì Set up rate limiting
‚úì Implement authentication for MCP server
‚úì Test disaster recovery procedures
‚úì Document your schema and patterns

Troubleshooting
Common issues and solutions.

Installation Issues
Native module build errors
If you encounter build errors, ensure you have:

‚Ä¢ Node.js 16+ installed
‚Ä¢ Python 3.x available in PATH
‚Ä¢ Build tools (node-gyp, make, gcc)

npm install --build-from-source
Performance Issues
Slow query performance
Solutions:

‚Ä¢ Lower efSearch parameter (trade accuracy for speed)
‚Ä¢ Reduce vector dimensions if possible
‚Ä¢ Use filtering before vector search
‚Ä¢ Consider using approximate search
High memory usage
Solutions:

‚Ä¢ Use disk storage instead of memory
‚Ä¢ Lower M parameter in HNSW config
‚Ä¢ Reduce maxElements limit
‚Ä¢ Implement data pruning
Database Issues
Database corruption
Recovery steps:


// 1. Create backup
cp agent.db agent.db.backup

// 2. Try repair
const db = new AgentDB({ 
  path: './agent.db',
  repair: true 
});

// 3. If repair fails, rebuild from backup
await db.rebuildIndex();
Browser Issues
WASM not loading
Check:

‚Ä¢ Browser supports WebAssembly
‚Ä¢ CORS headers are properly configured
‚Ä¢ WASM file is accessible
‚Ä¢ Content-Type header is correct
Need More Help?
GitHub Issues
Report bugs or request features

Open Issue
Community
Join discussions and get help

